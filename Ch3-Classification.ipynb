{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76373cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "assert sys.version_info >= (3, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b56be12",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fa3e24745aa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1.0.1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from packaging import version\n",
    "import sklearn\n",
    "\n",
    "assert version.parse(sklearn.__version__) >= version.parse(\"1.0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04cc46ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the default font sizes to make the figures prettier:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9044a71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And let's create the images/classification folder (if it doesn't already exist), and define the save_fig() function which is used through this notebook to save the figures in high-res for the book:\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "IMAGES_PATH = Path() / \"images\" / \"classification\"\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59a831dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch data from openml\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adbabfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Author**: Yann LeCun, Corinna Cortes, Christopher J.C. Burges  \n",
      "**Source**: [MNIST Website](http://yann.lecun.com/exdb/mnist/) - Date unknown  \n",
      "**Please cite**:  \n",
      "\n",
      "The MNIST database of handwritten digits with 784 features, raw data available at: http://yann.lecun.com/exdb/mnist/. It can be split in a training set of the first 60,000 examples, and a test set of 10,000 examples  \n",
      "\n",
      "It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting. The original black and white (bilevel) images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.  \n",
      "\n",
      "With some classification methods (particularly template-based methods, such as SVM and K-nearest neighbors), the error rate improves when the digits are centered by bounding box rather than center of mass. If you do this kind of pre-processing, you should report it in your publications. The MNIST database was constructed from NIST's NIST originally designated SD-3 as their training set and SD-1 as their test set. However, SD-3 is much cleaner and easier to recognize than SD-1. The reason for this can be found on the fact that SD-3 was collected among Census Bureau employees, while SD-1 was collected among high-school students. Drawing sensible conclusions from learning experiments requires that the result be independent of the choice of training set and test among the complete set of samples. Therefore it was necessary to build a new database by mixing NIST's datasets.  \n",
      "\n",
      "The MNIST training set is composed of 30,000 patterns from SD-3 and 30,000 patterns from SD-1. Our test set was composed of 5,000 patterns from SD-3 and 5,000 patterns from SD-1. The 60,000 pattern training set contained examples from approximately 250 writers. We made sure that the sets of writers of the training set and test set were disjoint. SD-1 contains 58,527 digit images written by 500 different writers. In contrast to SD-3, where blocks of data from each writer appeared in sequence, the data in SD-1 is scrambled. Writer identities for SD-1 is available and we used this information to unscramble the writers. We then split SD-1 in two: characters written by the first 250 writers went into our new training set. The remaining 250 writers were placed in our test set. Thus we had two sets with nearly 30,000 examples each. The new training set was completed with enough examples from SD-3, starting at pattern # 0, to make a full set of 60,000 training patterns. Similarly, the new test set was completed with SD-3 examples starting at pattern # 35,000 to make a full set with 60,000 test patterns. Only a subset of 10,000 test images (5,000 from SD-1 and 5,000 from SD-3) is available on this site. The full 60,000 sample training set is available.\n",
      "\n",
      "Downloaded from openml.org.\n"
     ]
    }
   ],
   "source": [
    "# extra code â€“ it's a bit too long\n",
    "print(mnist.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e6eb1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = mnist.data, mnist.target\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bad98d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "#70000 total images and each image has 784 features as each image is 28*28 pixels. Each pixel represents one pixel's intensity from 0(white) to 255(black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b537f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5', '0', '4', ..., '4', '5', '6'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbc616a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdd2ff4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#look at one digit from dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_digit(image_data):\n",
    "    image = image_data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap=\"binary\") #binary gives grayscale colormap where 0 is white and 255 is black\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "some_digit = X[0]\n",
    "plot_digit(some_digit)\n",
    "save_fig(\"some_digit_plot\")  # extra code\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ca7105c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e65bb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "#Create test set and set it asside. Training set has first 60000 images and test set has last 10000 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd92aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try to identify one digit for now\n",
    "y_train_5 = (y_train == '5')  # True for all 5s, False for all other digits\n",
    "y_test_5 = (y_test == '5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d84ef4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use SGDClassifier (Stochastic gradient descent) as it deals with training instances one at a time which makes it well suited for online learning\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b546fae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use it to detect images of number 5\n",
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03cff6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95035, 0.96035, 0.9604 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Measuring Accuracy Using Cross-Validation. \n",
    "from sklearn.model_selection import cross_val_score #k-fold cross validation with 3 folds. split training set into 3 folds and train the model 3 times\n",
    "\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\n",
    "#Above 95% accuracy on all cross-validation folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "994242b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier()\n",
    "dummy_clf.fit(X_train, y_train_5)\n",
    "print(any(dummy_clf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "420aa6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90965, 0.90965, 0.90965])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the accuracy of non-5 images using dummyclassifier\n",
    "cross_val_score(dummy_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\n",
    "#Accuracy is not a preferred performance measure for classifiers, use confusion matrix instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfc0537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COnfusion matrix - count number of times instances of Class A classified as class B for all A/B pairs. e.g count number of times classifier confused images of 8 with 0\n",
    "#for this we need set of actual predictions to compare with actual targets use cross_val_predict() function for this\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3) #makes predictions made on each test fold\n",
    "y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2df5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use confusion matrix and pass it the target class (y_train_5) and prediction class (y_train_pred)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_train_5, y_train_pred)\n",
    "cm\n",
    "#each row represents an actual class while each column represents a predicted class\n",
    "#first row considers non-5 images (negative class): 53892 correctly classified as non-5 (true negatives),687 wrongly classified as 5s (false positive, type 1 error)\n",
    "#second row considers images of 5 (positive class): 1891 wrongly classified as non-5 (false negatives type II errors), 3530 correctly classified as 5s (true positive)\n",
    "#Perfect classifier would only have true positives and true negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1c0a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_perfect_predictions = y_train_5  # pretend we reached perfection\n",
    "confusion_matrix(y_train_5, y_train_perfect_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7110f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other way is to use precision and recall. precision = TP/(TP+FP) is used with recall (which is ratio of positive instances correctly detected by classifier) recall = TP/(TP+FN)\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_train_5, y_train_pred)  # == 3530 / (687 + 3530)\n",
    "#It is correct only 83.7% of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dd5fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train_5, y_train_pred)  # == 3530 / (1891 + 3530)\n",
    "#It only detects 65.1% of the 5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cbaf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#F1-score = harmonic mean of precision and recall. Single metric to compare two classifiers\n",
    "#F1 score = 2 * ((precision * recall)/(precision + recall))\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27615b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#precision-recall tradeoff: as precision increases recall decreases and vice versa\n",
    "#we can have access to decision scores it uses to make predictions using decision_function() which returns score for each instance, then use any threshold to make predictions\n",
    "y_scores = sgd_clf.decision_function([some_digit])\n",
    "y_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6e49dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0 #SGDClassifier uses threshold = 0, so this returns same result as predict()\n",
    "y_some_digit_pred = (y_scores > threshold)\n",
    "y_some_digit_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f937f346",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 3000\n",
    "y_some_digit_pred = (y_scores > threshold)\n",
    "y_some_digit_pred\n",
    "#raising threshold decreases recall. Image actually represents 5 and classifier detects it when threshold = 0. Fails to detect when threshold increased = 3000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4c531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use cross_val_predict() to get scores of all instances on training set and specify we want decision score\n",
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3,\n",
    "                             method=\"decision_function\")\n",
    "y_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e343627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use precision_recall_curve() to compute precision and recall for all possible thresholds\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2f1750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use matplotlib to plot precision and recall as functions of threshold value\n",
    "plt.figure(figsize=(8, 4))  # formatting\n",
    "plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
    "plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "plt.vlines(threshold, 0, 1.0, \"k\", \"dotted\", label=\"threshold\")\n",
    "\n",
    "#  beautifies and saves Figure \n",
    "idx = (thresholds >= threshold).argmax()  # first index â‰¥ threshold\n",
    "plt.plot(thresholds[idx], precisions[idx], \"bo\")\n",
    "plt.plot(thresholds[idx], recalls[idx], \"go\")\n",
    "plt.axis([-50000, 50000, 0, 1])\n",
    "plt.grid()\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.legend(loc=\"center right\")\n",
    "save_fig(\"precision_recall_vs_threshold_plot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a129e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#can plot precision directly against recall\n",
    "import matplotlib.patches as patches  # for the curved arrow\n",
    "\n",
    "plt.figure(figsize=(6, 5))  #formatting\n",
    "\n",
    "plt.plot(recalls, precisions, linewidth=2, label=\"Precision/Recall curve\")\n",
    "\n",
    "# extra code â€“ just beautifies and saves Figure 3â€“6\n",
    "plt.plot([recalls[idx], recalls[idx]], [0., precisions[idx]], \"k:\")\n",
    "plt.plot([0.0, recalls[idx]], [precisions[idx], precisions[idx]], \"k:\")\n",
    "plt.plot([recalls[idx]], [precisions[idx]], \"ko\",\n",
    "         label=\"Point at threshold 3,000\")\n",
    "plt.gca().add_patch(patches.FancyArrowPatch(\n",
    "    (0.79, 0.60), (0.61, 0.78),\n",
    "    connectionstyle=\"arc3,rad=.2\",\n",
    "    arrowstyle=\"Simple, tail_width=1.5, head_width=8, head_length=10\",\n",
    "    color=\"#444444\"))\n",
    "plt.text(0.56, 0.62, \"Higher\\nthreshold\", color=\"#333333\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.grid()\n",
    "plt.legend(loc=\"lower left\")\n",
    "save_fig(\"precision_vs_recall_plot\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fdb3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#suppose we aim for 90% precision, we can search for lowest threshold using numpy's argmax() that will give at least 90% precision\n",
    "idx_for_90_precision = (precisions >= 0.90).argmax()\n",
    "threshold_for_90_precision = thresholds[idx_for_90_precision]\n",
    "threshold_for_90_precision\n",
    "#returns first index of maximum value, first True Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b84d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to make predictions (on training set for now), instead of calling predict() can use this\n",
    "y_train_pred_90 = (y_scores >= threshold_for_90_precision)\n",
    "y_train_pred_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb051b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_train_5, y_train_pred_90)\n",
    "#90% precision is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53c8b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_at_90_precision = recall_score(y_train_5, y_train_pred_90)\n",
    "recall_at_90_precision\n",
    "#48% recall not at all good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff08b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC curve Receiver Operating Characteristic plots true positive rate (recall) against false positive rate (FPR also called fallout)\n",
    "#Fallout = ratio of negative instances incorrectly classified as positive = 1- TNR. TNR true negative rate = ratio of negative instances correctly classified as negative\n",
    "#TNR also called as specificity. ROC thus plots sensitivity(recall) versus 1-specificity\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccf56d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FPR against TPR using matplotlib\n",
    "idx_for_threshold_at_90 = (thresholds <= threshold_for_90_precision).argmax()\n",
    "tpr_90, fpr_90 = tpr[idx_for_threshold_at_90], fpr[idx_for_threshold_at_90]\n",
    "\n",
    "plt.figure(figsize=(6, 5))  # extra code â€“ not needed, just formatting\n",
    "plt.plot(fpr, tpr, linewidth=2, label=\"ROC curve\")\n",
    "plt.plot([0, 1], [0, 1], 'k:', label=\"Random classifier's ROC curve\")\n",
    "plt.plot([fpr_90], [tpr_90], \"ko\", label=\"Threshold for 90% precision\")\n",
    "\n",
    "# beautifies and saves Figure\n",
    "plt.gca().add_patch(patches.FancyArrowPatch(\n",
    "    (0.20, 0.89), (0.07, 0.70),\n",
    "    connectionstyle=\"arc3,rad=.4\",\n",
    "    arrowstyle=\"Simple, tail_width=1.5, head_width=8, head_length=10\",\n",
    "    color=\"#444444\"))\n",
    "plt.text(0.12, 0.71, \"Higher\\nthreshold\", color=\"#333333\")\n",
    "plt.xlabel('False Positive Rate (Fall-Out)')\n",
    "plt.ylabel('True Positive Rate (Recall)')\n",
    "plt.grid()\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.legend(loc=\"lower right\", fontsize=13)\n",
    "save_fig(\"roc_curve_plot\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76315cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One way to compare classifiers is to measure area under the curve AUC. perfect classifier will have ROC AUC = 1\n",
    "#purely random qualifier will have a ROC AUC = 0.5\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_train_5, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7528b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's create RandomForestClassifier and compare its PR curve snd F1 score with those of SDGClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de88d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use predict_proba() that returns class probablities and use them as scores\n",
    "y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3,\n",
    "                                    method=\"predict_proba\") #use cross_val_predict()\n",
    "y_probas_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f8cc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas_forest[:2]\n",
    "#predicts first image is positive with 89% probability and second image is negative with 99% probability\n",
    "#probabilities in each row add up to 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58373539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are estimated probabilities. Among the images that the model classified as positive with a probability between 50% and 60%, there are actually about 94% positive images:\n",
    "idx_50_to_60 = (y_probas_forest[:, 1] > 0.50) & (y_probas_forest[:, 1] < 0.60)\n",
    "print(f\"{(y_train_5[idx_50_to_60]).sum() / idx_50_to_60.sum():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19af595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#second column contains estimated probabilities for positive class, let's pass them to precision_recall_curve() function\n",
    "y_scores_forest = y_probas_forest[:, 1]\n",
    "precisions_forest, recalls_forest, thresholds_forest = precision_recall_curve(\n",
    "    y_train_5, y_scores_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8912b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot PR curve\n",
    "plt.figure(figsize=(6, 5))  # formatting\n",
    "\n",
    "plt.plot(recalls_forest, precisions_forest, \"b-\", linewidth=2,\n",
    "         label=\"Random Forest\")\n",
    "plt.plot(recalls, precisions, \"--\", linewidth=2, label=\"SGD\")\n",
    "\n",
    "#  beautifies and saves Figure\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.grid()\n",
    "plt.legend(loc=\"lower left\")\n",
    "save_fig(\"pr_curve_comparison_plot\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#random forest classifier is superior to SGD because it's PR curve is much closer to top-right corner and has greater AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11136ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_forest = y_probas_forest[:, 1] >= 0.5  # positive proba â‰¥ 50%\n",
    "f1_score(y_train_5, y_train_pred_forest)\n",
    "#f1 score better than SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c803310",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_train_5, y_scores_forest)\n",
    "#auc better than SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e42b090",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train_5, y_train_pred_forest)\n",
    "#recall score better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72858e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_train_5, y_train_pred_forest)\n",
    "#precision score better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0adda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's try multiclass classification using binary classifier. \n",
    "#Scikit detects when we use binary classifier for multiclass and automatically runs OvR (one-vs-the-rest) or OvO (One-vs-One)\n",
    "#Here we used support vector machine classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(random_state=42)\n",
    "svm_clf.fit(X_train[:2000], y_train[:2000])  # y_train, not y_train_5 and train only first 2000 images\n",
    "\n",
    "#OvO strategy used and trained 45 classifiers = (10-1)*10/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10f886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's make prediction on image\n",
    "svm_clf.predict([some_digit])\n",
    "#this made 45 predictions and selected the class that won most duels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5936ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's call decision_function() to check it returns 10 scores per instance per class. Score = number of duels won + or - small tweak (max +- 0.33)\n",
    "some_digit_scores = svm_clf.decision_function([some_digit])\n",
    "some_digit_scores.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ec610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Highest score = 9.3 corresponding to digit 5. Let's check using argmax()\n",
    "class_id = some_digit_scores.argmax()\n",
    "class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ae8f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After classifier is trained, target classes are stored in its classes_ attributes\n",
    "svm_clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809d7227",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf.classes_[class_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510bbaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows how to get all 45 OvO scores if needed\n",
    "svm_clf.decision_function_shape = \"ovo\"\n",
    "some_digit_scores_ovo = svm_clf.decision_function([some_digit])\n",
    "some_digit_scores_ovo.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb61dcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if we want to specifically use OvO or OvR,can use OneVsOneClassifier or OnevsRestClassifier, create an instance and pass a classifier to it's constructor\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "ovr_clf = OneVsRestClassifier(SVC(random_state=42))\n",
    "ovr_clf.fit(X_train[:2000], y_train[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d33a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's make prediction\n",
    "ovr_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d6c3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ovr_clf.estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab21a3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training an SGDClassifier on multiclass dataset\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "sgd_clf.predict([some_digit])\n",
    "\n",
    "#prediction error!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61d6229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scikit used OvR strategy, since there are 10 classes, it trained 10 binary classifiers\n",
    "#lets look at scores SGD Classifier assigned to each class using decision_function()\n",
    "\n",
    "sgd_clf.decision_function([some_digit]).round()\n",
    "\n",
    "#classifier not confident about its prediction as all scores are negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ad8141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val_score() to evaluate the model\n",
    "cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "\n",
    "#85.8% accuracy on all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ac13d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#can increase the accuracy by scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(\"float64\"))\n",
    "cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f83dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions using cross_val_predict() and pass it through confusion matrix\n",
    "#Let's look at the diagram to understand the errors better\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\n",
    "plt.rc('font', size=9)  # extra code â€“ make the text smaller\n",
    "ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7f2773",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_a, cl_b = '3', '5'\n",
    "X_aa = X_train[(y_train == cl_a) & (y_train_pred == cl_a)]\n",
    "X_ab = X_train[(y_train == cl_a) & (y_train_pred == cl_b)]\n",
    "X_ba = X_train[(y_train == cl_b) & (y_train_pred == cl_a)]\n",
    "X_bb = X_train[(y_train == cl_b) & (y_train_pred == cl_b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8357ebb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generates and saves Figure\n",
    "#can use it to analyze prediction errors\n",
    "size = 5\n",
    "pad = 0.2\n",
    "plt.figure(figsize=(size, size))\n",
    "for images, (label_col, label_row) in [(X_ba, (0, 0)), (X_bb, (1, 0)),\n",
    "                                       (X_aa, (0, 1)), (X_ab, (1, 1))]:\n",
    "    for idx, image_data in enumerate(images[:size*size]):\n",
    "        x = idx % size + label_col * (size + pad)\n",
    "        y = idx // size + label_row * (size + pad)\n",
    "        plt.imshow(image_data.reshape(28, 28), cmap=\"binary\",\n",
    "                   extent=(x, x + 1, y, y + 1))\n",
    "plt.xticks([size / 2, size + pad + size / 2], [str(cl_a), str(cl_b)])\n",
    "plt.yticks([size / 2, size + pad + size / 2], [str(cl_b), str(cl_a)])\n",
    "plt.plot([size + pad / 2, size + pad / 2], [0, 2 * size + pad], \"k:\")\n",
    "plt.plot([0, 2 * size + pad], [size + pad / 2, size + pad / 2], \"k:\")\n",
    "plt.axis([0, 2 * size + pad, 0, 2 * size + pad])\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "save_fig(\"error_analysis_digits_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b64f8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multilabel Classification\n",
    "#used to output multiple classes for each instance (e.g face recognition)\n",
    "#creates multilabel array containing 2 target labels for each digit\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "y_train_large = (y_train >= '7') # - first indicates whether digit is large (7,8,9)\n",
    "y_train_odd = (y_train.astype('int8') % 2 == 1) #indicates whether its odd\n",
    "y_multilabel = np.c_[y_train_large, y_train_odd] #creates multilabel array with these 2 target labels\n",
    "\n",
    "knn_clf = KNeighborsClassifier() #creates KNeighborsClassifier() and trains model using multiple targets array\n",
    "knn_clf.fit(X_train, y_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c042a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions\n",
    "knn_clf.predict([some_digit])\n",
    "\n",
    "#digit 5 is not large but is odd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbcab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to evaluate multilabel classifier, one way is to measure f1 score for each individual label and compute the avg score\n",
    "y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3)\n",
    "f1_score(y_multilabel, y_train_knn_pred, average=\"macro\")\n",
    "\n",
    "#for face recognition, we will need an weighted average, that is, to give each label (face) a weight equal to its support (number of instances with that target label)\n",
    "f1_score(y_multilabel, y_train_knn_pred, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e23c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multioutput Classification\n",
    "#generalization pf multilabel classification where each label can be multiclass (can have more than 2 possible values)\n",
    "#let's build a system that removes noise from image - returns clean image\n",
    "\n",
    "#let's begin by creating training and test sets by taking MNIST images and adding noise to their pixel intensities with NumPy randint() function\n",
    "\n",
    "np.random.seed(42)  # to make this code example reproducible\n",
    "noise = np.random.randint(0, 100, (len(X_train), 784))\n",
    "X_train_mod = X_train + noise\n",
    "noise = np.random.randint(0, 100, (len(X_test), 784))\n",
    "X_test_mod = X_test + noise\n",
    "y_train_mod = X_train\n",
    "y_test_mod = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf76143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  generates and saves Figure \n",
    "plt.subplot(121); plot_digit(X_test_mod[0])\n",
    "plt.subplot(122); plot_digit(y_test_mod[0])\n",
    "save_fig(\"noisy_digit_example_plot\")\n",
    "plt.show()\n",
    "\n",
    "#noisy image on the left and clean image on the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ee24e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train_mod, y_train_mod)\n",
    "clean_digit = knn_clf.predict([X_test_mod[0]])\n",
    "plot_digit(clean_digit)\n",
    "save_fig(\"cleaned_digit_example_plot\")  # extra code â€“ saves Figure 3â€“13\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c854827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ab3ced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd66a612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dc0a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97f9e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b5e484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ed01eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b410686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
